{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "032f4207",
   "metadata": {},
   "source": [
    "# STARTUP NAME / Data Analysis Project (SANTA BARBARA ANALYTICA XD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cfaf0d",
   "metadata": {},
   "source": [
    "## Scope of work\n",
    "\n",
    "### 1. Introducción\n",
    "\n",
    "En este documento se describe el proceso de análisis de datos, herramientas que pueden usarse en el desarrollo de un proyecto para mantener la reproducibilidad, un desglose de como usar los recursos para que el proyecto sea realizado en la nube y finalmente una comparación en los costos de estos servicios por parte de diferentes proveedores de PaaS.\n",
    "### 2. Planteamiento del problema\n",
    "Actualmente se dice que los datos son el nuevo \"petroleo\" o \"electricidad\". Nos encontramos en la era de los datos, por lo tanto se estan usando en todos los campos, banca, universidades, marketing (agregar mas supongo). Actualmente se espera que en los proximos años la demanda de daas o servicios de analisis de datos siga en aumento.\n",
    "\n",
    "### 3. Justificación\n",
    "Nuestra startup busca entrar en un mercado con mucha demanda, que seguira en aumento. Actualmente las empresas mas grandes en el rubro ocupan ayuda de terceros en la limpieza y analis de los datos, ya que son las partes del proceso de analis de datos mas demandantes en tiempo.\n",
    "\n",
    "### 4. Objetivos\n",
    "\n",
    "- Como analistas de datos nuestro objetivo es seguir el proceso de analisis para recolectar, organizar y transformar datos. Para llegar a conclusiones basadas en datos que puedan ayudar a una organizacion, universidad, empresa, compañia o persona a tomar las mejores desiciones.\n",
    "\n",
    "- En el futuro esperamos ofrecer servicios de ciencia de datos enfocados en la investigacion, donde esperamos usar datasets para hacer predicciones e inferencias estadisticas usando modelos de machine learning y deep learning\n",
    "\n",
    "### 5. Marco Teorico\n",
    "\n",
    "Hay diversas formas para desarrollar un proyecto basado en analisis de datos. El procedimiento a seguir varia dependiendo de la organizacion. En nuestra Startup usamos el siguiente:\n",
    "1. Definir el problema: Hacer preguntas para entender las expectativas y el problema que las partes interesadas (stakeholders) quieren resolver. Entender cual es el propósito.\n",
    "2. Recolectar y Almacenar los Datos: Si es necesario establecer como los datos serán recolectados, pero también definir como serán almacenados, si es necesario hacer backups, si los datos son confidenciales como deben ser tratados y si es necesario al finalizar el proyecto estos deben destruirse. Si los datos ya están recolectados, establecer las fuentes, si fueron recolectados internamente por la organización o fueron recolectados externamente por terceros, esto debido a que es necesario definir la confiabilidad de los datos. (** Revisar Huawei Cloud services o cualquier empresa que ofresca saas, iass, pass ...etc)\n",
    "3. Procesamiento: En esta etapa, una vez se tienen los datos ya sea en formato CSV o en una base de datos es necesario revisarlos, encontrar errores, limpairlos datasets para eliminar valores atípicos que puedan sesgar el análisis. (Spreadsheets, SQL, BigQuery... etc)\n",
    "4. Analisis: Usar herramientas para transformar y organizar la informacion, de tal manera que se pueda concluir o hacer predicciones basadas en datos. (Python, R, Jupyter)\n",
    "5. Visualización: Presentar los datos de una manera facil de entender para las partes interesadas, usando gráficos, mapas, dashboards. (Tableau, PowerBI)\n",
    "6. Entregar a las partes interesadas para que ellos puedan tomar las decisiones\n",
    "\n",
    "#### En un proyecto real  primero se define el problema y se hacen preguntas especificas\n",
    "\n",
    "Definiendo el problema:\n",
    "- ¿Cual es el problema?\n",
    "- ¿Puede ser resuelto con data? ¿Que tipo de data?\n",
    "- ¿Donde esta esta data? ¿Existe, se debe de recoletar?\n",
    "- ¿Esta data es publica o privada?\n",
    "- ¿Quienes estan involucrados? ¿Quienes son los stakeholders?\n",
    "- ¿Cuales son los limites del proyecto?\n",
    "\n",
    "El objetivo de las preguntas es obtener informacion, que puede ser usada para obtener conocimientos y con ellos resolver problemas. Es recomendable realizar preguntas especificas y que sus respuestas sean medibles y cuantificadas. Ya que la información obtenida sera cuantitativa o cualitativa.   \n",
    "\n",
    "\n",
    "#### Recolectando datos\n",
    "\n",
    "Si los datos no serán recolectados internamente, es necesario comprobar la validez y confiabilidad de ellos. Preguntarse ¿Quien? ¿Donde? ¿Cuando? fueron recolectados.\n",
    "\n",
    "Si los datos serán recolectados internamente hay que definir un intervalo de tiempo, que tipos de datos son necesarios y la cantidad a recolectar. \n",
    "\n",
    "En general, se debe asegurar que los datos presentan la menor cantidad de bias posible, que sean originales, actualizados, citados y seguros. Es muy importante tener en cuenta la etica al cuando se maneha informacion de terceros, ya que algunos datos son propiedad del cliente, no de la empresa. Los recursos finales deben enviarse entregarse a los clientes o como es debido en la etapa final del ciclo de vida de los datos, destruirse.\n",
    "\n",
    "#### Procesando datos\n",
    "\n",
    "Cuando se procesan datos, lo mas importante es mantener la integridad de los mismos. Es necesario que los datos sean correctos, los datasets completos, consistentes y confiables. Normalmente la limpieza de los datos se da en spreadsheets o en una base de datos, hay que tener en cuenta que en la limpieza los datos serán replicados, transferidos y manipulados en el proceso. También, es necesario tomar en cuenta la población, si se usa una muestra, que la muestra tenga un nivel de confianza mayor al 95% y un margen de error pequeño de tal modo que los datos tengan una significancia estadística alta. Una vez que se comprueba la significancia estadística, se procede a limpiar. Para ello se usan diversas herramientas en spreadsheets y funciones en SQL.\n",
    "\n",
    "#### Analizando datos\n",
    "\n",
    "Una vez los datos están limpios y en un formato útil estos pueden ser organizados (en tablas y bases de datos que permiten manipulación, filtrar y clasificación). Datos organizados son información que puede ser analizada por medio de cálculos y modelamiento para encontrar tendencias, relaciones, patrones y correlaciones entre los datos.\n",
    "\n",
    "Una herramienta importante en esta etapa es la agregación de datos, esto permite juntar datos de múltiples fuentes para poder combinarlos en una sola colección sumarizada. \n",
    "\n",
    "#### Visualizando datos\n",
    "\n",
    "En esta etapa los datos se muestran a las partes interesadas en graficos, dashboards o mapas. Estas visualizaciones deben ser efectivas, convincentes y faciles de entender.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Los elementos mas importantes pueden resumirse en la siguiente tabla**\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Item</th>\n",
    "    <th>Herramientas</th>\n",
    "    <th>Observación</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Adquisición de datos</td>\n",
    "    <td>Data co-op, web scraping, compra a terceros, encuestas, public data, open data</td>\n",
    "    <td>Los datos pueden ser obtenidos de los mismos clientes, se pueden usar servicios para web scraping o tambien comprar los datos a terceros</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Transformación de datos</td>\n",
    "    <td>Herramientas para agregacion de datos, VLOOKUP en spreadsheets, Join() en SQL</td>\n",
    "    <td>Es uno de los elementos mas importantes ya que los datos pueden provenir de muchas fuentes por lo tanto es nececsario juntar los datos para poder encontrar correlaciones</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Entrega de datos</td>\n",
    "    <td>Bases de datos</td>\n",
    "    <td>Como el cliente tiene acceso a los datos</td>\n",
    "  </tr>\n",
    "  \n",
    "</table>\n",
    "\n",
    "### 6. Metodología \n",
    "\n",
    "Aqui agregar la rubrica establecida y como se usarian los 100 tokens. Hacer una comparativa de precios/servicios entre diferentes compañias (AWS, HUAWEI, AZURE, GCLOUD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea624396",
   "metadata": {},
   "source": [
    "### Recursos a tomar en cuenta\n",
    "\n",
    "### Open Source o de Acceso Gratuito\n",
    "aqui definir la parte de la tarea: **Resources you can get for free (Open Data, Open software, Open Access, volunteer computing,...)**\n",
    "\n",
    "#### Notebooks y PaaS\n",
    "- Ambiente de desarrollo para ciencias de datos [anaconda navigator](https://www.anaconda.com/)\n",
    "- Para escribir notebooks y realizar analicis en la nube [project jupyter](https://jupyter.org/), tambien en [google colab](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjlyp67gbbyAhVxQjABHfyXC_oQFnoECBUQAw&url=https%3A%2F%2Fresearch.google.com%2Fcolaboratory%2F&usg=AOvVaw38J01zt_Dlb6pQ1fe6FGrI) se puede usar computo (CPUs, GPUs) para ejecutar notebooks usando jupyter.\n",
    "- En una imagen de una maquina virtual se puede compactar específicamente los recursos necesarios para el análisis de datos, se puede crear la imagen solo con herramientas de acceso gratuito(GNU/LINUX, Jupyter ...etc)\n",
    "- [Docker](https://hub.docker.com/) permite ejecutar en contenedores jupyter con diversas librerías de tal manera que no es necesario una instalación completa de ambientes como ser anaconda.\n",
    "- [Bynder](https://mybinder.org/) permite convertir un repositorio de git en notebooks ejecutables ofrecicendo recursos de computo al usuario\n",
    "\n",
    "#### Datasets \n",
    "- En cuentas oficiales de gobierno se puede encontrar open data, esto significa que ya esta estructurada y bien mantenida. También, puede usarse el repositorio de [opendatanetwork](https://www.opendatanetwork.com/) \n",
    "- Alrededor de la web también puede encontrarse public data, que seria toda data que se encuentra en el dominio publico, normalmente no esta estructurada. Hay diversas plataformas de datos públicos en las cuales se puede obtener data, como ser: [kaggle](https://www.kaggle.com/), [kdnuggets](https://www.kdnuggets.com/), [google cloud public datasets](https://cloud.google.com/public-datasets), [google datasearch](https://datasetsearch.research.google.com/) \n",
    "- En [papers with code](https://paperswithcode.com/) puede encontrarse artículos de investigación en el campo de ciencias de datos con los datasets usados en el paper\n",
    "\n",
    "#### Repositorios\n",
    "- [git](https://git-scm.com/) es una herramienta usada para control de versiones, actualmente es un estándar en DevOps. Algunas de las web mas usadas para mantener repositorios y proyectos de desarrollo son: [GitHub](https://github.com/), [GitLab](https://about.gitlab.com/), [Bitbucket](https://bitbucket.org/product)\n",
    "\n",
    "#### Limpieza y Analisis\n",
    "La herramienta a usar para la limpieza de los datos depende del tamaño de los datos:\n",
    "- Para small data normalmente es suficiente usar spreadsheets ya sea usando google sheets, microsoft excel, CALC de libre office o cualquier software que pueda ejecutar documentos separados por coma.\n",
    "- Para el análisis lo mas usado es python y R, aunque no son los únicos lenguajes en los cuales puede realizarse el modelamiento tienen la ventaja y facilidad que sus kernels pueden ser usados fácilmente en notebooks.\n",
    "\n",
    "### Herramientas de Pago\n",
    "\n",
    "\n",
    "Aqui definir la parte de la tarea:\n",
    "* Discuss how and why you will allocate those resources to make a sustainable and reproducible infrastructure and/or analysis pipelines\n",
    "* Use estimation based in public offer/prices and the knowledge about the Open Access resources learned in the course\n",
    "* You can imagine this is the budget for one (1) year of operations\n",
    "* Let's limitate the analysis to resources like: Software and Hardware\n",
    "\n",
    "#### Visualización de Datos\n",
    "La forma de presentar los datos es muy importante, para ello se debe tomar en cuenta a quien va dirigido el análisis o presentación.\n",
    "\n",
    "- El método de [McCandless](https://www.informationisbeautiful.net/visualizations/what-makes-a-good-data-visualization/) para visualización de datos, divide el proceso en diferentes elementos que juntos generan una buena visualización.\n",
    "- También, puede usarse un repositorio de visualizaciones para investigar que tipo seria el adecuado para el dataset que se este analizando, [repositorio de visualizaciones](https://informationisbeautiful.net/)\n",
    "- Algunas de las herramientas mas usadas son Tableau y Power BI, ambas son de pago por suscripción\n",
    "\n",
    "| Herramienta | Descripcion | Price/month ($) |  \n",
    "|--------------- -|-------------|------------| \n",
    "| Tableau| Herramienta para visualización de datos desplegada en la nube | 42 por usuario |\n",
    "| Power BI | Herramienta para visualización de datos| 20 por usuario | \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Limpieza y Analisis\n",
    "La herramienta a usar para la limpieza de los datos depende del tamaño de los datos:\n",
    "- Para BigData es necesario usar bases de datos para mantener los datasets, en análisis de datos normalmente se usan bases de datos relacionales ya que los datos deben organizarse de forma estructural por lo tanto pueden usarse diversos proveedores de Bases de Datos en la nube, estos servicios son de pago.\n",
    "\n",
    "\n",
    "#### Servicios en la Nube\n",
    "\n",
    "En general estos servidores en la nube proporcionan recursos informáticos escalables y bajo demanda para aplicaciones seguras, flexibles y eficientes\n",
    "\n",
    "- Actualmente diversas compañías ofrecen IaaS, PasS y SaaS como servicios por demanda en la nube. Amazon Web Services, Microsoft Azure, Huawei Cloud Services y Google Cloud son algunos de los proveedores de estos servicios. En Amazon los servidores se llaman EC2 (Amazon Elastic Compute Cloud), en Huawei se llaman ECS (Elastic Cloud Servers), en Azure se llaman Azure Vms (Azure Virtual Machines). Las tres también ofrecen servicios para instancias de Bases de Datos con diversos dialectos de SQL. Google Cloud por su parte ofrece un servicio especial para análisis de datos en su consola, llamado BigQuery. BigQuery es una plataforma para análisis de datos sin servidor ya que no es necesario crear instancias individuales o máquinas virtuales para usar BigQuery. En su lugar, BigQuery asigna recursos informáticos automáticamente cuando sean necesarios, por lo tanto es un servicio mucho mas simple de utilizar y el tiempo usado en la configuración, adaptación y migración es mínimo comparado con el tiempo dedicado en crear las instancias de servidores en las otras compañías ya que se requiere mas entrenamiento para la configuración y uso correcto de las consolas en AWS, AZURE Y HUAWEI. Por tal razón para este proyecto se decidió que usar el servicio de BigQuery para administrar y mantener los datos estructurados en RDB seria lo mas eficiente a nivel de costo/beneficio y facilidad de uso ya que solo es necesario subir los datasets a la nube y rápidamente en la misma consola se hacen los queries necesarios sin configurar nada mas. \n",
    "\n",
    "Tabla comparativa de costos de diversas instancias de servidores de computo AWS, AZURE, HUAWEI \n",
    "\n",
    "GNU/LINUX\n",
    "\n",
    "| OS | Tipo de servicio | Descripcion | Price/Hour ($) | Compañia \n",
    "| -- | --------------- -|-------------|------------|---------| \n",
    "| Linux | General Purpose | 4 CPUs, 16GB RAM | 0.1856 | AWS |\n",
    "| Linux | General Purpose | 4 CPUs, 16GB RAM | 0.28 | HUAWEI |\n",
    "| Linux | General Purpose | 4 CPUs, 16GB RAM | 0.1670 | AZURE |\n",
    "\n",
    "\n",
    "| OS | Tipo de servicio | Descripcion | Price/Hour ($) | Compañia \n",
    "| -- | --------------- -|-------------|------------|---------| \n",
    "| Linux | Memory Optimized | 4 CPUs, 16GB RAM | 0.2660 | AWS |\n",
    "| Linux | Memory Optimized | 4 CPUs, 32GB RAM | 0.3900 | HUAWEI |\n",
    "| Linux | Memory Optimized | 4 CPUs, 16GB RAM | 0.2660 | AZURE |\n",
    "\n",
    "| OS | Tipo de servicio | Descripcion | Price/Hour ($) | Compañia \n",
    "| -- | --------------- -|-------------|------------|---------| \n",
    "| Linux | GPU Accelerated | 4 GPUs, 16GB RAM, 64vCPUs | 3.68 | AWS |\n",
    "| Linux | GPU Accelerated | 1 NVIDIA V100-16Q / 16G, 32vCPUs | 5.89 | HUAWEI |\n",
    "\n",
    "\n",
    "WINDOWS\n",
    "\n",
    "| OS | Tipo de servicio | Descripcion | Price/Hour ($) | Compañia \n",
    "| -- | --------------- -|-------------|------------|---------| \n",
    "| Windows | General Purpose | 4 CPUs, 16GB RAM | 0.8560 | AWS |\n",
    "| Windows | General Purpose | 4 CPUs, 16GB RAM | 0.43 | HUAWEI |\n",
    "| Windows | General Purpose | 4 CPUs, 16GB RAM | 0.5970 | AZURE |\n",
    "\n",
    "\n",
    "| OS | Tipo de servicio | Descripcion | Price/Hour ($)| Compañia \n",
    "| -- | --------------- -|-------------|------------|---------| \n",
    "| Windows | Memory Optimized | 4 CPUs, 16GB RAM | 0.9520 | AWS |\n",
    "| Windows | Memory Optimized | 4 CPUs, 16GB RAM | 0.57 | HUAWEI |\n",
    "| Windows | Memory Optimized | 4 CPUs, 16GB RAM | 0.85 | AZURE |\n",
    "\n",
    "| OS | Tipo de servicio | Descripcion | Price/Hour ($) | Compañia \n",
    "| -- | --------------- -|-------------|------------|---------| \n",
    "| Windows | GPU Accelerated | 4 GPUs, 16GB RAM, 48vCPUs | 6.12 | AWS |\n",
    "| Windows | GPU Accelerated | 1 NVIDIA V100-16Q / 16G, 32vCPUs | 7.40 | HUAWEI |\n",
    "\n",
    "\n",
    "Tabla comparativa de costos de diversas instancias de servidores de base de datos MySQL AWS, AZURE, HUAWEI \n",
    "\n",
    "| Deployment Option | Tier | Compute | Storage | Backup | Price/Month ($)| Compañia \n",
    "| -- | --------------- -|-------------|------------|---------|---------|----------|\n",
    "| Single Server | General Purpose | 4vCPUs, 16 RAM | 1024 GB | 1024 GB| 658.07 | AWS |\n",
    "| Single Server | General Purpose | 4vCPUs, 16 RAM | 1024 GB | 1024 GB| 426.95 | HUAWEI |\n",
    "| Single Server | General Purpose | Gen 5 4vCore | 1024 GB | 1024 GB| 475.95 | AZURE |\n",
    "\n",
    "\n",
    "\n",
    "**Nota: Tomar en cuenta que otros costos deben ser agregados como ser direccion ip, ancho de banda, arquitectura de los CPUs, tipo de servidor y otros elementos en la configuracion de las instancias. Tambien, es necesario un entrenamiento para poder configurar y usar correctamente los diversos servicios ofrecidos por AWS, AZURE y HUAWEI**\n",
    "\n",
    "\n",
    "\n",
    "### Precios de BigQuery en Google Cloud\n",
    "\n",
    "En BigQuery cada proyecto está vinculado a una cuenta de facturación. Todos los cargos que se aplican a BigQuery por las tareas que se ejecutan en el proyecto se facturan en dicha cuenta. Se puede usar el servicio bajo demanda que en este modelo de precios, se debe pagar especificamente por la cantidad de bytes procesados por cada consulta tanto si los datos se almacenan en BigQuery como si se guardan en una fuente de datos externa, ya que se basa únicamente en el uso, el primer TB de datos de consultas procesado del mes es gratuito. Tambien hay planes mensuales y anuales, donde  el precio es más bajo.\n",
    "\n",
    "Los precios de BigQuery tienen dos componentes principales:\n",
    "\n",
    "- El precio de análisis: es el coste de procesar consultas, como las consultas SQL, las funciones definidas por el usuario, las secuencias de comandos y determinadas instrucciones de lenguajes de manipulacion de datasets.\n",
    "\n",
    "\n",
    "|Opción | Operación | Detalles | Price ($)| Compañia| \n",
    "| -- | --------------- -|-------------|---------|-----|\n",
    "| Bajo demanda | Consultas, Queries | El primer TB del mes es gratis | 5 por TB | Google |\n",
    "| Tarifa fija a corto plazo | Consultas, Queries | Se pueden cancelar las ranuras flexibles y solo se paga por los segundos que haya estado desplegado el compromiso | 4/hora por 100 ranuras | Google |\n",
    "\n",
    "\n",
    "- El precio de almacenamiento: es el coste de almacenar los datos en BigQuery. Se paga por el almacenamiento activo y a largo plazo.\n",
    "    - El almacenamiento activo incluye todas las particiones de tablas y tablas que se hayan modificado en los últimos 90 días.\n",
    "    - El almacenamiento a largo plazo incluye cualquier tabla o partición de tabla que no se haya modificado durante 90 días consecutivos. El precio de almacenamiento de esa tabla se reduce automáticamente en alrededor de un 50 %. No hay ninguna diferencia en el rendimiento, la durabilidad o la disponibilidad entre el almacenamiento activo y a largo plazo.\n",
    "\n",
    "\n",
    "| Operación | Detalles | Price ($)| Compañia | \n",
    "| ----------------|-------------|---------|-----|\n",
    "|Almacenamiento activo | Los primeros 10 GB del mes son gratuitos | 0.020 por GB | Google |\n",
    "| Almacenamiento a largo plazo | Los primeros 10 GB del mes son gratuitos | 0.010 por GB | Google |\n",
    "\n",
    "Para almacenar 1 TB durante un mes entonces el costo seria 20.48$.\n",
    "\n",
    "#### VPN en google cloud\n",
    "\n",
    "Por seguridad podria usarse un tunel VPN con IPsec para realizar las consultas y envio de los datos, el costo seria de 184$ por mes tomando en cuenta el pago por la puerta de enlace y 1TB de trafico de salida que pasara por el tunel\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d4524",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
